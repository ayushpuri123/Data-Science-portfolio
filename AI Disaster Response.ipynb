{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0ccacecb",
      "metadata": {
        "id": "0ccacecb"
      },
      "source": [
        "\n",
        "## Introduction\n",
        "\n",
        "Natural disasters often require quick and efficient rescue operations to minimize casualties and damage.\n",
        "\n",
        "I will focus on applying genetic algorithms, ant colony optimization, the Minmax algorithm with alpha-beta pruning and its enhancements, multi-agent systems, game theory, and Bayesian networks. These methods will help you simulate decision-making in multi-agent rescue operations. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9220620f",
      "metadata": {
        "id": "9220620f"
      },
      "source": [
        "## Simulation Scenario\n",
        "\n",
        "An earthquake has struck NovaCity, causing widespread destruction, including fires, and road blockages. Emergency response teams need to be coordinated for rescue operations.\n",
        "\n",
        "The city is divided into **5 regions (R1 to R5)**. Each region has an evaluated **damage level** according to its blocked roads and fires:\n",
        "- High damage (H): $>=50\\%$ roads blocked, or $>=30\\%$ fires;\n",
        "- Medium damage (M): $[10\\%, 50\\%)$ roads blocked, or $[10\\%, 30\\%)$ fires; and\n",
        "- Low damage (L): $<10\\%$ roads blocked, or $<10\\%$ fires.\n",
        "\n",
        "Either blocked roads or fires that reach the range can be considered its damage level. For example, a region with 30\\% road blocks and 5\\% fires is Medium damaged.\n",
        "\n",
        "The **initial damage** to each region is provided:\n",
        "- R1 (H): 60\\% roads blocked, 35\\% fires;\n",
        "- R2 (M): 40\\% roads blocked, 25\\% fires;\n",
        "- R3 (M): 15\\% roads blocked, 5\\% fires;\n",
        "- R4 (H): 35\\% roads blocked, 30\\% fires; and\n",
        "- R5 (L): 5\\% roads blocked, 3\\% fires.\n",
        "\n",
        "Assume all regions are of equal size to simplify the modelling process. Each region is modelled as a **node** in a graph, and predefined **distances** between regions (e.g., 5 km between R1 and R2, 3 km between R2 and R3) are detailed: R1 -- R2: 5 km, R1 -- R3: 7 km, R1 -- R4: 4 km, R1 -- R5: 6 km, R2 -- R3: 3 km, R2 -- R4: 4 km, R2 -- R5: 8 km, R3 -- R4: 5 km, R3 -- R5: 6 km, and R4 -- R5: 4 km.\n",
        "\n",
        "During the rescue, each region will continue to experience fire spread and aftershocks. Fires spread every 10 minutes within the same region, increasing the fire percentage by 10\\%. Aftershocks occur randomly every 15 minutes increasing road blockages by 10\\% over all regions. For example, in R1, the initial damage is 60\\% roads blocked and 35\\% fires. After 10 minutes, it becomes $(60\\%, 45\\%)$, and after an additional 5 minutes, it becomes $(70\\%, 45\\%)$ if no rescue operations are performed.\n",
        "\n",
        "Rescue agents are distributed across regions at the start of the simulation. **Eight units of fire trucks start at R2.** Each fire truck unit decreases fire percentage by 10\\% per rescue operation. **Six units of police start at R4.** Each police unit decreases road blockages by 10\\% per rescue operation. Multiple agents/units can perform rescue operations at the same time in the same region. The effects of their actions are cumulative. For example, if 2 fire trucks are deployed to R1 simultaneously, the fire percentage decreases by 20\\% in one operation. Rescue operations affect the regional damage directly. If a fire truck reduces fire percentage by 10\\%, that 10\\% decrease is applied to the overall fire damage in that region, e.g., $20\\%-10\\%=10\\%$.\n",
        "\n",
        "**Assumption:** Both rescue operations and disaster events (fire spread and aftershocks) do not consume time in this simulation, but each unit can only perform rescue once when visiting the region. Rescue agents will not lose resources along a path, and all operations will occur instantly for the purpose of modelling. However, the effects of disasters and rescues will still be cumulative over time. Rescue agents aim to follow a path that covers all regions, ensuring each region is visited only once. After completing their assigned rescue tasks along the path, they must return to their starting point for a refill.\n",
        "\n",
        "**Travel Speed:** Rescue agents can travel at a maximum speed of 60 km/h on unblocked roads. If roads are blocked, their speed will be reduced according to the percentage of blocked roads in the region they are traveling to or from. The travel speed between two regions is determined by the average percentage of blocked roads in both regions. For example, if R1 has 60\\% blocked roads and R2 has 40\\% blocked roads, the average blocked road percentage is $(60\\% + 40\\%) / 2 = 50\\%$. The travel speed will then be reduced by 50\\%, resulting in a travel speed of 30 km/h. Rescue agents won’t block each other. Fire damage will not affect travel speed.\n",
        "\n",
        "Rescue operations must be completed within 90 minutes and the sooner the better. You need to allocate resources efficiently, prioritize critical regions, and adapt to changing conditions like fire spread and aftershocks. Rescue agents must quickly respond to new blockages and worsening fires, adjusting strategies to minimize delays."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48cf2111",
      "metadata": {
        "id": "48cf2111"
      },
      "source": [
        "## Task Breakdown and their Objectives\n",
        "\n",
        "1. **Genetic Algorithms for Path Optimization**: Implement a genetic algorithm to design and develop efficient pathfinding algorithms that help rescue agents navigate disaster environments quickly and effectively. The implementation should use multiple successors to improve path selection and minimize overall rescue time.\n",
        "\n",
        "2. **Ant Colony Optimization (ACO) for Multi-Agent Coordination**:  Simulate how each rescue unit (e.g., polices and fire trucks) employs ACO to coordinate their movements to find their optimal paths. Assume agents can communicate in real time to share updated road and fire conditions once they arrive at the scene. The simulation should dynamically update “pheromone levels” as new road blockages or fires occur, improving the collaboration of multi-agent systems to ensure optimal use of resources and timely responses in disaster scenarios.\n",
        "\n",
        "3. **Minmax Algorithm with Alpha-Beta Pruning and Enhancements**: Implement the Minmax algorithm with Alpha-Beta Pruning to improve decision-making in competitive rescue scenarios, e.g., rescue agent vs fire spread/aftershock. Additionally, explore further computational enhancements, such as negamax or other advanced modifications of your design, to optimize the evaluation of rescue strategies, e.g, the number of units should be assigned to the same location, and improve decision-making efficiency.\n",
        "\n",
        "4. **Game Theory for Multi-Agent Systems**: Model an uncertain strategy by assigning predefined parameters specific values using game theory. Identify an appropriate equilibrium (such as Nash equilibrium, dominant strategy equilibrium, or another relevant concept) to maximize overall success.\n",
        "\n",
        "5. **Bayesian Networks for Uncertain Inferences**: Develop Bayesian networks to handle uncertainties in rescue operations, such as fire spread or road blockages. Use Conditional Probability Tables (CPTs) to model incomplete information and support agents in making better-informed decisions under evolving conditions.\n",
        "\n",
        "The objectives may not be developed in sequence. As you work through the assignment, keep the overall design of the solution in mind and carefully consider where each method or solution best fits to achieve the overall project goals."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba642903",
      "metadata": {
        "id": "ba642903"
      },
      "source": [
        "## Assignment Requirements\n",
        "\n",
        "1. **Overall Project Title and Design**: Begin by naming your project and reporting your overall project design. Describe how you plan to approach the disaster response simulation as a whole.\n",
        "\n",
        "2. **Linking Tasks to the Design**: Clearly explain how each task (genetic algorithms, ACO, Minmax, game theory, Bayesian networks) fits into your overall design. Show how these tasks are expected to contribute to solving the problem.\n",
        "\n",
        "3. **Task-Specific Design**: For each task, provide detailed explanations of your approach, including any required calculations, step-by-step explanations, and referenced equations. Your written design should clearly describe how you will tackle each specific task.\n",
        "\n",
        "4. **Code Development**: Provide the corresponding code that fully implements both your task-specific design and the overall project design. You don’t need to repeat the same code in multiple sections, but you must reference and explain the code clearly in your design reporting. This ensures that your written report ties directly into your coding implementation, showing how the code achieves the project goals and the performance of each individual task.\n",
        "\n",
        "5. **Submission**: The final submission should be in the Jupyter Notebook format (.ipynb) that you downloaded. Once completed, submit this notebook as your final submission. Initial contents like instructions can be removed in your final submission. Use Markdown cells to write your design report, including explanations, calculations, and step-by-step approaches. The code for each task should be placed in the corresponding code cells, ensuring it’s well-integrated with the report. Organize your notebook clearly using appropriate heading structures. Use: # for Level 1 (main headings), ## for Level 2 (subheadings), ### for Level 3 (sub-subheadings), etc. Ensure that all code in the notebook is fully executable. Each section’s code should output relevant results that support the design made in the report. The notebook should be easy to navigate. Use comments within your code to explain key parts of the implementation where necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3abe391d",
      "metadata": {
        "id": "3abe391d"
      },
      "source": [
        "## Marking Guidelines\n",
        "\n",
        "- **Overall design (10 marks)**: Clear and well-structured overall project design. Proper linkage of tasks to the overall solution. Thoughtful consideration of how each method fits into the project’s goals.\n",
        "\n",
        "- **Breakdown Tasks**: Clear explanation of the design and approaches in the report and correct implementation by coding.\n",
        "    - Task 1: Genetic Algorithms (15 marks)\n",
        "    - Task 2: ACO (15 marks)\n",
        "    - Task 3: Minmax Algorithm (20 marks)\n",
        "    - Task 4: Game Theory (15 marks)\n",
        "    - Task 5: Bayesian Networks (15 marks).\n",
        "\n",
        "- **Clarity and Style for Report and Code (10 marks)**: Clear, well-structured report that explains the design and tasks effectively. Proper organization using headings and step-by-step explanations. Well-commented and easy-to-read code. Code runs correctly and produces the expected results for each task."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35bfdcf8",
      "metadata": {
        "id": "35bfdcf8"
      },
      "source": [
        "## Special Consideration and Late Submissions\n",
        "\n",
        "Unless a Special Consideration request has been submitted and approved, a **5% penalty** (ofthe total possible mark) will be applied each day a written assessment is not submitted, upuntil the 7th day (including weekends). After the 7th day, a grade of '0' will be awarded evenif the assessment is submitted. Submission time for all written assessments is set at **11:55pm**. A 1-hour grace period is provided to students who experience a technical concern.\n",
        "\n",
        "For any late submission of time-sensitive tasks, such as scheduled tests/exams, performance assessments/presentations, and/or scheduled practical assessments/labs, students need to submit an application for Special Consideration.\n",
        "\n",
        "- Assignment 1: YES, Standard Late Penalty applies\n",
        "- **Assignment 2: YES, Standard Late Penalty applies**\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e61fe965",
      "metadata": {
        "id": "e61fe965"
      },
      "source": [
        "_Below is the start of your Assignment 2. Edition over provided structure is allowed. Instructions and hints can be removed in your final submission._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f353075",
      "metadata": {
        "id": "0f353075"
      },
      "source": [
        "# Project Title: Enhanced Disaster Response through AI-Driven Optimization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cf1d036",
      "metadata": {
        "id": "8cf1d036"
      },
      "source": [
        "_Author details_\n",
        "\n",
        "- Student Name: Ayush Puri\n",
        "- ID Number: 47369655\n",
        "- Email Address: ayush.puri@students.mq.edu.au"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdb497f8",
      "metadata": {
        "id": "cdb497f8"
      },
      "source": [
        "# Overall Design"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f5f622f",
      "metadata": {
        "id": "2f5f622f"
      },
      "source": [
        "\n",
        "The aim of this project is to simulate and optimize a coordinated response to an earthquake in NovaCity using a multi-method AI approach. This involves strategically deploying fire trucks and police units to manage fire spread and clear blocked roads. The design combines genetic algorithms, ant colony optimization, the Minimax algorithm with alpha-beta pruning, game theory, and Bayesian networks to create an interconnected system that adapts to changing conditions. Each method shares data and insights with others, forming a cohesive, iterative process that ensures optimal decision-making throughout the simulation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fffb734",
      "metadata": {
        "id": "3fffb734"
      },
      "source": [
        "## Task Breakdown\n",
        "\n",
        "### Task 2: ACO for Multi-Agent Coordination\n",
        "\n",
        "**Goal**: Coordinate rescue units effectively by simulating how they choose paths, optimizing resource allocation, and responding to real-time changes like road blockages and fires.\n",
        "\n",
        "**Integration:**\n",
        "\n",
        "- Input: Initial region data, road blockage and fire percentages, predefined distances.\n",
        "\n",
        "- Output: Optimized rescue paths for agents with updated pheromone trails based on travel outcomes.\n",
        "\n",
        "- Next Step: Use these optimized paths as the initial population in Task 1 (Genetic Algorithms).\n",
        "\n",
        "### Task 1: Genetic Algorithms for Path Optimization\n",
        "\n",
        "**Goal**: Evolve the initial population of rescue paths to minimize overall rescue time and ensure efficient region coverage.\n",
        "\n",
        "**Integration:**\n",
        "\n",
        "- Input: Paths generated from ACO with pheromone levels indicating suitability.\n",
        "\n",
        "- Output: Optimized path sequences for agents that account for road blockages and fire levels.\n",
        "\n",
        "- Next Step: Provide these paths to Task 3 (Minmax Algorithm) for strategic analysis.\n",
        "\n",
        "### Task 3: Minmax Algorithm with Alpha-Beta Pruning\n",
        "\n",
        "**Goal**: Improve decision-making by evaluating rescue strategies against the potential spread of fires and occurrence of aftershocks.\n",
        "\n",
        "**Integration:**\n",
        "\n",
        "- Input: Optimized paths from the genetic algorithm, data on fire spread and aftershock probabilities.\n",
        "\n",
        "- Output: Refined strategy recommendations for the deployment of agents, including unit allocation.\n",
        "\n",
        "- Next Step: Utilize the strategy for resource allocation modeling in Task 4 (Game Theory).\n",
        "\n",
        "### Task 4: Game Theory for Multi-Agent Systems\n",
        "\n",
        "**Goal**: Model resource allocation strategies using game theory concepts to maximize success in uncertain conditions.\n",
        "\n",
        "**Integration:**\n",
        "\n",
        "- Input: Strategy outputs from the Minmax algorithm.\n",
        "\n",
        "- Output: Optimal resource distribution strategies, potentially finding Nash equilibria or dominant strategies.\n",
        "\n",
        "- Next Step: Feed these strategies into Task 5 (Bayesian Networks) for handling uncertainties.\n",
        "\n",
        "### Task 5: Bayesian Networks for Uncertain Inferences\n",
        "\n",
        "**Goal**: Use Bayesian networks to manage uncertainty and improve decision-making when dealing with dynamic elements such as fire spread and aftershocks.\n",
        "\n",
        "**Integration:**\n",
        "\n",
        "- Input: Strategies from game theory and updated data on fire and blockage probabilities.\n",
        "\n",
        "- Output: Probabilistic insights and recommendations to adjust strategies based on real-time data.\n",
        "\n",
        "- Next Step: Feedback loop to Task 2 (ACO) for continuous path and strategy adjustments."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61e794db",
      "metadata": {
        "id": "61e794db"
      },
      "source": [
        "# Breakdown Tasks\n",
        "\n",
        "### Reordered Task Sequence Based on Overall Design:\n",
        "\n",
        "1. Task 2\n",
        "2. Task 1\n",
        "3. Task 3\n",
        "4. Task 4\n",
        "5. Task 5\n",
        "\n",
        "\n",
        "Following this structure, the project ensures that each component builds on the previous one, creating a robust and adaptable disaster response system for NovaCity. Each method complements the others, resulting in a cohesive framework that enhances the overall effectiveness of emergency response."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7383378",
      "metadata": {
        "id": "d7383378"
      },
      "source": [
        "## Task 2: Ant Colony Optimization (ACO) for Multi-Agent Coordination"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b6df3a9",
      "metadata": {
        "id": "4b6df3a9"
      },
      "source": [
        "report your design here. A step follows a piece of code is preferred.\n",
        "\n",
        "_hints:_ Fire trucks and polices need to be handled seperately when implementing ACO.\n",
        "\n",
        "Similar to the calculation of the averaged blockages between two regions, the pheromone level can be determined by averaging the conditions of the two connected regions. For example, $\\rho^{\\text{fire}}_{R_1R_2} = 1 - [\\text{fire damage}(R1)+\\text{fire damage}(R2)]/2/100$.\n",
        "\n",
        "Additionally, the equations are provided for your convenience in reporting.\n",
        "\n",
        "$$\\tau_{ij} \\leftarrow \\text{Evaporation}(\\tau_{ij})$$\n",
        "\n",
        "$$\\tau_{ij} \\leftarrow \\text{Rescue}(\\tau_{ij})$$ where `Evaporation` can be fire spread or aftershock, `Rescue` can be from a unit of fire truck or a unit of police.\n",
        "\n",
        "$$\\eta_{ij}=1/d_{ij}$$\n",
        "\n",
        "$$p^k_{ij}=\\frac{[\\tau_{ij}]^\\alpha[\\eta_{ij}]^\\beta}{\\sum_{l\\in N_k(i)}[\\tau_{il}]^\\alpha[\\eta_{il}]^\\beta}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "37e0b0d2",
      "metadata": {
        "id": "37e0b0d2"
      },
      "outputs": [],
      "source": [
        "# provide your code here\n",
        "# around 5 simple functions are needed to complete this task.\n",
        "# evaporate_pheromones\n",
        "# deposit_pheromones\n",
        "# choose_next_region\n",
        "# edge_travel_time\n",
        "# simulate_agent_path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f49ceecd",
      "metadata": {
        "id": "f49ceecd"
      },
      "source": [
        "#### Step 1: Establish Parameters and Initial Configuration\n",
        "The first step sets key parameters for the ACO algorithm, including the weights for pheromone and heuristic influence, the pheromone evaporation rate, and the number of agents. We also need to initialize the data for regions, distances between them, and their respective damage levels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "3c03ae19",
      "metadata": {
        "id": "3c03ae19"
      },
      "outputs": [],
      "source": [
        "# Necessary Libraries\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Parameter Configuration\n",
        "alpha = 1                  # Weight for pheromone influence\n",
        "beta = 2                   # Weight for heuristic influence\n",
        "evaporation_rate = 0.5     # Rate of pheromone evaporation per iteration\n",
        "pheromone_deposit = 10     # Pheromone amount added after each path completion\n",
        "num_iterations = 50        # Total simulation cycles\n",
        "num_agents = 8             # Total number of agents (e.g., fire trucks, police units)\n",
        "\n",
        "# Initial Data Setup\n",
        "regions = ['R1', 'R2', 'R3', 'R4', 'R5']\n",
        "distances = {\n",
        "    ('R1', 'R2'): 5, ('R2', 'R1'): 5,\n",
        "    ('R1', 'R3'): 7, ('R3', 'R1'): 7,\n",
        "    ('R1', 'R4'): 4, ('R4', 'R1'): 4,\n",
        "    ('R1', 'R5'): 6, ('R5', 'R1'): 6,\n",
        "    ('R2', 'R3'): 3, ('R3', 'R2'): 3,\n",
        "    ('R2', 'R4'): 4, ('R4', 'R2'): 4,\n",
        "    ('R2', 'R5'): 8, ('R5', 'R2'): 8,\n",
        "    ('R3', 'R4'): 5, ('R4', 'R3'): 5,\n",
        "    ('R3', 'R5'): 6, ('R5', 'R3'): 6,\n",
        "    ('R4', 'R5'): 4, ('R5', 'R4'): 4\n",
        "}\n",
        "\n",
        "# Damage levels in each region represented as tuples (fire severity, road blockage in %)\n",
        "damage_levels = {'R1': (60, 35), 'R2': (40, 25), 'R3': (15, 5), 'R4': (35, 30), 'R5': (5, 3)}\n",
        "\n",
        "# Initial pheromone levels for all paths\n",
        "pheromones = {edge: 1 for edge in distances}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JgvyoecEmu3J",
      "metadata": {
        "id": "JgvyoecEmu3J"
      },
      "source": [
        "#### Step 2: Define the `evaporate_pheromones` Function\n",
        "This function models the pheromone evaporation process, decreasing pheromone levels across all paths at the end of each iteration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "XIGBk0vvm3DR",
      "metadata": {
        "id": "XIGBk0vvm3DR"
      },
      "outputs": [],
      "source": [
        "def evaporate_pheromones():\n",
        "    # Reduce pheromone levels on all paths to simulate evaporation.\n",
        "    for edge in pheromones:\n",
        "        pheromones[edge] *= (1 - evaporation_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "k033YOvxnGxq",
      "metadata": {
        "id": "k033YOvxnGxq"
      },
      "source": [
        "#### Step 3: Define the `deposit_pheromones` Function\n",
        "The `deposit_pheromones` function adds pheromones along the path an agent has traveled, reinforcing these routes to help guide future agents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "IswZta-BnjR9",
      "metadata": {
        "id": "IswZta-BnjR9"
      },
      "outputs": [],
      "source": [
        "def deposit_pheromones(path):\n",
        "    # Add pheromone levels along the agent's path.\n",
        "    for i in range(len(path) - 1):\n",
        "        edge = (path[i], path[i + 1])\n",
        "        if edge in pheromones:\n",
        "            pheromones[edge] += pheromone_deposit"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aqPDRKgtmc6E",
      "metadata": {
        "id": "aqPDRKgtmc6E"
      },
      "source": [
        "#### Step 4: Define the `edge_travel_time` Function\n",
        "This function computes the travel time between two regions, factoring in the average road blockage. The travel speed is adjusted based on the blockage percentage.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "Pia7c9t3mfS3",
      "metadata": {
        "id": "Pia7c9t3mfS3"
      },
      "outputs": [],
      "source": [
        "# Initialize cache to store travel times\n",
        "travel_time_cache = {}\n",
        "\n",
        "def edge_travel_time(region1, region2):\n",
        "    # Calculate the travel time between two regions, considering average road blockage.\n",
        "    if region1 == region2:\n",
        "        return 0  # No travel time is required if both regions are the same.\n",
        "\n",
        "    # Check if the result is already cached\n",
        "    if (region1, region2) in travel_time_cache:\n",
        "        return travel_time_cache[(region1, region2)]\n",
        "    if (region2, region1) in travel_time_cache:  # Check reverse order\n",
        "        return travel_time_cache[(region2, region1)]\n",
        "\n",
        "    # Calculate the average blockage between the two regions\n",
        "    avg_blockage = (damage_levels[region1][0] + damage_levels[region2][0]) / 2\n",
        "    effective_speed = 60 * (1 - avg_blockage / 100)  # Adjust speed (in km/h) for blockage\n",
        "\n",
        "    # Ensure distances are defined for the region pair\n",
        "    if (region1, region2) not in distances and (region2, region1) not in distances:\n",
        "        raise ValueError(f\"Distance between {region1} and {region2} is not defined.\")\n",
        "\n",
        "    # Retrieve the distance, accommodating both direction pairs\n",
        "    distance = distances.get((region1, region2), distances.get((region2, region1)))\n",
        "\n",
        "    # Calculate travel time in minutes\n",
        "    travel_time = distance / (effective_speed / 60)  # Convert km/h to km/min\n",
        "\n",
        "    # Cache the result\n",
        "    travel_time_cache[(region1, region2)] = travel_time\n",
        "    travel_time_cache[(region2, region1)] = travel_time  # Cache for both directions\n",
        "\n",
        "    return travel_time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3IWnjqOWnqtL",
      "metadata": {
        "id": "3IWnjqOWnqtL"
      },
      "source": [
        "#### Step 5: Define the `choose_next_region` Function\n",
        "This function selects the next region for an agent based on weighted probabilities, incorporating both pheromone levels and heuristic values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "wYUT46Djnwj3",
      "metadata": {
        "id": "wYUT46Djnwj3"
      },
      "outputs": [],
      "source": [
        "def choose_next_region(current_region, visited):\n",
        "    # Select the next region based on calculated probabilities.\n",
        "    probabilities = []\n",
        "    total_sum = 0\n",
        "\n",
        "    for region in regions:\n",
        "        if region != current_region and region not in visited:\n",
        "            # Determine the edge between current and target region\n",
        "            edge = (current_region, region) if (current_region, region) in pheromones else (region, current_region)\n",
        "            pheromone_level = pheromones[edge]\n",
        "            heuristic_value = 1 / edge_travel_time(current_region, region)\n",
        "            # Calculate probability based on pheromone and heuristic influence\n",
        "            probability = (pheromone_level ** alpha) * (heuristic_value ** beta)\n",
        "            probabilities.append((region, probability))\n",
        "            total_sum += probability\n",
        "\n",
        "    # Normalize the probabilities\n",
        "    probabilities = [(region, prob / total_sum) for region, prob in probabilities]\n",
        "\n",
        "    # Select the next region based on the weighted probability\n",
        "    next_region = random.choices(\n",
        "        [region for region, _ in probabilities],\n",
        "        [prob for _, prob in probabilities]\n",
        "    )[0]\n",
        "\n",
        "    return next_region"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "C7BRkPHaoJ2B",
      "metadata": {
        "id": "C7BRkPHaoJ2B"
      },
      "source": [
        "#### Step 6: Define the `simulate_agent_path` Function\n",
        "This function simulates the path taken by an agent from its starting region, selecting new regions until all have been visited, then returning to the starting point.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "1WLehN5KoLkd",
      "metadata": {
        "id": "1WLehN5KoLkd"
      },
      "outputs": [],
      "source": [
        "def simulate_agent_path(start_region, pheromone_levels, exploration_factor):\n",
        "    path = [start_region]\n",
        "    current_region = start_region\n",
        "    \n",
        "    while len(path) < len(damage_levels):\n",
        "        # Determine next region, sometimes choosing randomly based on exploration factor\n",
        "        if random.random() < exploration_factor:\n",
        "            next_region = random.choice([region for region in damage_levels if region not in path])\n",
        "        else:\n",
        "            next_region = choose_next_region(current_region, path)\n",
        "        \n",
        "        path.append(next_region)\n",
        "        current_region = next_region\n",
        "    \n",
        "    path.append(start_region)  # Return to the starting region\n",
        "    return path\n",
        "\n",
        "# Set up start region and number of agents\n",
        "start_region = 'R1'  # Specify the appropriate starting region\n",
        "num_agents = 5       # Set the desired number of agents"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84bcfc23",
      "metadata": {
        "id": "84bcfc23"
      },
      "source": [
        "## Task 1: Genetic Algorithms for Path Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af9361f2",
      "metadata": {
        "id": "af9361f2"
      },
      "source": [
        "report your design here. A step follows a piece of code is preferred.\n",
        "\n",
        "_hints:_ The successor of exchange might fit more to this project than mutation. Successor works on `path[1:]` as the start location is fixed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "3c7e9736",
      "metadata": {
        "id": "3c7e9736"
      },
      "outputs": [],
      "source": [
        "# provide your code here\n",
        "# around 7 simple functions are needed to complete this task.\n",
        "# generate_initial_population\n",
        "# fitness_function\n",
        "# selection\n",
        "# crossover\n",
        "# exchange\n",
        "# successor\n",
        "# genetic_algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j-Ck9yOfp3Ai",
      "metadata": {
        "id": "j-Ck9yOfp3Ai"
      },
      "source": [
        "#### Step 1: Define the `generate_initial_population` Function\n",
        "The first step is to create an initial set of potential paths. Each path represents a sequence of regions that an agent might travel, beginning and ending at a fixed starting location.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "dpNwNvaOp4dC",
      "metadata": {
        "id": "dpNwNvaOp4dC"
      },
      "outputs": [],
      "source": [
        "def generate_initial_population(size, regions):\n",
        "    # Generate an initial collection of paths.\n",
        "    population = []\n",
        "    for _ in range(size):\n",
        "        path = [regions[0]] + random.sample(regions[1:], len(regions) - 1) + [regions[0]]\n",
        "        population.append(path)\n",
        "    return population\n",
        "\n",
        "# Example usage:\n",
        "initial_population = generate_initial_population(6, regions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ulv52M6vqdWm",
      "metadata": {
        "id": "Ulv52M6vqdWm"
      },
      "source": [
        "#### Step 2: Define the `fitness_function`\n",
        "The `fitness_function` evaluates each path based on the total travel time. A shorter travel time indicates a better fitness score, as it represents a more efficient route."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "nEYMI5XEqhbG",
      "metadata": {
        "id": "nEYMI5XEqhbG"
      },
      "outputs": [],
      "source": [
        "def fitness_function(path):\n",
        "    # Compute the fitness of a path based on the cumulative travel time.\n",
        "    total_time = 0\n",
        "    for i in range(len(path) - 1):\n",
        "        total_time += edge_travel_time(path[i], path[i + 1])\n",
        "    return 1 / total_time  # Fitness is the inverse of travel time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "diey_8tPqqs5",
      "metadata": {
        "id": "diey_8tPqqs5"
      },
      "source": [
        "#### Step 3: Define the `selection` Function\n",
        "The selection function identifies parent paths for crossover based on their fitness, with higher fitness paths having a greater likelihood of being chosen.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "Tzbp8XB-qqHq",
      "metadata": {
        "id": "Tzbp8XB-qqHq"
      },
      "outputs": [],
      "source": [
        "def selection(population, fitness_scores):\n",
        "    # Select two parents using a probability weighted by fitness scores.\n",
        "    total_fitness = sum(fitness_scores)\n",
        "    probabilities = [score / total_fitness for score in fitness_scores]\n",
        "    parents = random.choices(population, weights=probabilities, k=2)\n",
        "    return parents\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PoOuPmnJsHAb",
      "metadata": {
        "id": "PoOuPmnJsHAb"
      },
      "source": [
        "#### Step 4: Define the `crossover` Function\n",
        "The crossover function combines two parent paths to create a new child path, ensuring the offspring inherits characteristics from both parents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "ZfwI-OyhsIs7",
      "metadata": {
        "id": "ZfwI-OyhsIs7"
      },
      "outputs": [],
      "source": [
        "\n",
        "def crossover(parent1, parent2):\n",
        "    # Generate an offspring path by merging segments of the two parent paths.\n",
        "    start = 1\n",
        "    end = random.randint(1, len(parent1) - 2)\n",
        "    child = parent1[:start] + [gene for gene in parent2 if gene not in parent1[:start]]\n",
        "\n",
        "    # Ensure each region appears only once in the path\n",
        "    missing_regions = set(parent1) - set(child)\n",
        "    child.extend(missing_regions)\n",
        "\n",
        "    return child"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Nsz7pITOsO4P",
      "metadata": {
        "id": "Nsz7pITOsO4P"
      },
      "source": [
        "#### Step 5: Define the `exchange` Function\n",
        "The `exchange` function swaps the positions of two regions in a path, introducing variation and exploring different solutions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "Fx12v6Q7sSzg",
      "metadata": {
        "id": "Fx12v6Q7sSzg"
      },
      "outputs": [],
      "source": [
        "def exchange(path):\n",
        "    # Perform a swap operation on a path.\n",
        "    idx1, idx2 = random.sample(range(1, len(path) - 1), 2)\n",
        "    path[idx1], path[idx2] = path[idx2], path[idx1]\n",
        "    return path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sVyWg1jysj4s",
      "metadata": {
        "id": "sVyWg1jysj4s"
      },
      "source": [
        "#### Step 6: Define the `successor` Function\n",
        "The `successor` function creates a new population by applying the `exchange` operation to each path in the current generation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "f3eZqjgbsldp",
      "metadata": {
        "id": "f3eZqjgbsldp"
      },
      "outputs": [],
      "source": [
        "def successor(population):\n",
        "    # Generate a new set of paths by performing the exchange operation on each path.\n",
        "    new_population = [exchange(path[:]) for path in population]\n",
        "    return new_population"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Zh9-oRMYssHT",
      "metadata": {
        "id": "Zh9-oRMYssHT"
      },
      "source": [
        "#### Step 7: Define the `genetic_algorithm` Function\n",
        "The main genetic algorithm function iterates through multiple generations, using selection, crossover, and exchange to evolve paths with higher fitness. To ensure that the best path found by the algorithm starts and ends at the designated starting region, a final check appends the starting point if it’s missing at the end. This guarantees the path maintains the correct structure.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "IuAbSPnBsvku",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuAbSPnBsvku",
        "outputId": "b9a75b9b-b2c1-4c1c-94c4-f31d3c9d54a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best path found: ['R1', 'R5', 'R4', 'R2', 'R3', 'R1']\n"
          ]
        }
      ],
      "source": [
        "def genetic_algorithm(initial_population, generations):\n",
        "    # Run the genetic algorithm to optimize the path.\n",
        "    population = initial_population\n",
        "    for generation in range(generations):\n",
        "        fitness_scores = [fitness_function(path) for path in population]\n",
        "        new_population = []\n",
        "\n",
        "        while len(new_population) < len(population):\n",
        "            parent1, parent2 = selection(population, fitness_scores)\n",
        "            child = crossover(parent1, parent2)\n",
        "            child = exchange(child)\n",
        "            new_population.append(child)\n",
        "\n",
        "        population = successor(new_population)\n",
        "\n",
        "    # Identify the best path based on fitness scores\n",
        "    fitness_scores = [fitness_function(path) for path in population]\n",
        "    best_path = population[fitness_scores.index(max(fitness_scores))]\n",
        "\n",
        "    # Ensure the best path completes the round trip\n",
        "    if best_path[-1] != best_path[0]:\n",
        "        best_path.append(best_path[0])\n",
        "\n",
        "    return best_path\n",
        "\n",
        "# Example usage:\n",
        "best_path = genetic_algorithm(initial_population, 21)\n",
        "print(\"Best path found:\", best_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09ac383f",
      "metadata": {
        "id": "09ac383f"
      },
      "source": [
        "## Task 3: Minmax Algorithm with Alpha-Beta Pruning and Enhancements"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae23ae49",
      "metadata": {
        "id": "ae23ae49"
      },
      "source": [
        "report your design here. A step follows a piece of code is preferred.\n",
        "\n",
        "_hints:_\n",
        "\n",
        "Who is **Max Player**?\n",
        "\n",
        "Who is **Min Player**?\n",
        "\n",
        "**Game tree construction** Any data should be prepared by pre-computation? Utility?\n",
        "\n",
        "|            |       |     |      |         |      |\n",
        "| ---------- |  -----|-----|------|-------- | -----|\n",
        "|`path[0]`   |  Max  |     |      |  #units   |    |\n",
        "|            |       |     |      |     l     |    |\n",
        "|            | Min   |     |      |     fires |    |\n",
        "|            |       |   / |    / |       l   | \\  |\n",
        "|`path[1]`   | Max   |  #units  | #units-1| ...|  1   |\n",
        "|            |       |   l |  l   |            |     |\n",
        "|            | Min   |fires|fires |  ...   |         |\n",
        "|`path[2]`   | ...   |  ...|//...l...\\\\   |   ...   |       |\n",
        "|      ...   |       |     | #units-1 .... 1     |  ...    |     |\n",
        "|`path[4]`   |  ...  | ... |  ... |  ...    |  ... |\n",
        "\n",
        "Start with total number of units of agents at `path[0]`. For each region `path[i]`, the number units of agents assigned can be from the available units at that point down to one. Compute all possible allocations for the regions (`path[1]`, `path[2]`, `path[3]`, `path[4]`) based on the remaining units after allocation at the current region. Recursively list all possible combinations of allocations along the path."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MYxUIAu1I8kf",
      "metadata": {
        "id": "MYxUIAu1I8kf"
      },
      "source": [
        "#### Step 1: Define the Players\n",
        "In this task, we define two types of players:\n",
        "\n",
        "- **Max Player**: Represents the rescue agents who aim to maximize the efficiency of resource allocation to reduce fire damage and clear blocked roads.\n",
        "- **Min Player**: Represents the adverse forces of disaster events (such as fires or aftershocks) that worsen the situation.\n",
        "\n",
        "Understanding the roles of the Max and Min players sets up a decision-making process where the Max player aims to optimize outcomes, while the Min player simulates challenging conditions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Huvj0E9sJRvw",
      "metadata": {
        "id": "Huvj0E9sJRvw"
      },
      "source": [
        "#### Step 2: Prepare Data for Game Tree Construction\n",
        "In this step, we create a game tree that represents possible allocations of units to regions along a path. This tree alternates between Max and Min nodes to simulate decision-making.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "3f167e83",
      "metadata": {
        "id": "3f167e83"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_game_tree(path, total_units):\n",
        "    # Construct a game tree with all possible unit allocations along the path.\n",
        "    game_tree = []\n",
        "\n",
        "    def helper(current_path, remaining_units, current_level):\n",
        "        if current_level == len(path):  # Base case: end of the path reached\n",
        "            game_tree.append(current_path[:])\n",
        "            return\n",
        "\n",
        "        for units in range(remaining_units, 0, -1):\n",
        "            current_path.append((path[current_level], units))\n",
        "            helper(current_path, remaining_units - units, current_level + 1)\n",
        "            current_path.pop()  # Backtrack to explore other allocations\n",
        "\n",
        "    helper([], total_units, 0)\n",
        "    return game_tree\n",
        "\n",
        "# Example usage:\n",
        "path = ['R1', 'R4', 'R5', 'R2', 'R3']\n",
        "total_units = 6  # Total number of units available for allocation\n",
        "game_tree = generate_game_tree(path, total_units)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "asqqlMgeJ_Le",
      "metadata": {
        "id": "asqqlMgeJ_Le"
      },
      "source": [
        "#### Step 3: Implement the Minmax Algorithm with Alpha-Beta Pruning\n",
        "The next step is to implement the Minmax algorithm with alpha-beta pruning to navigate the game tree, optimizing decisions for the Max player while considering responses from the Min player.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "TL8z0nS9JTaT",
      "metadata": {
        "id": "TL8z0nS9JTaT"
      },
      "outputs": [],
      "source": [
        "def minmax(node, depth, is_max_player, alpha, beta):\n",
        "    # Minmax algorithm with alpha-beta pruning.\n",
        "    if depth == 0 or is_terminal_node(node):\n",
        "        return evaluate_node(node)  # Return the utility value of the node\n",
        "\n",
        "    if is_max_player:\n",
        "        max_eval = float('-inf')\n",
        "        for child in generate_children(node):\n",
        "            eval = minmax(child, depth - 1, False, alpha, beta)\n",
        "            max_eval = max(max_eval, eval)\n",
        "            alpha = max(alpha, eval)\n",
        "            if beta <= alpha:\n",
        "                break  # Prune the branch with beta cut-off\n",
        "        return max_eval\n",
        "    else:\n",
        "        min_eval = float('inf')\n",
        "        for child in generate_children(node):\n",
        "            eval = minmax(child, depth - 1, True, alpha, beta)\n",
        "            min_eval = min(min_eval, eval)\n",
        "            beta = min(beta, eval)\n",
        "            if beta <= alpha:\n",
        "                break  # Prune the branch with alpha cut-off\n",
        "        return min_eval"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wmRt9qbvMBl2",
      "metadata": {
        "id": "wmRt9qbvMBl2"
      },
      "source": [
        "#### Step 4: Implement Supporting Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YFPTjeUFNJ1L",
      "metadata": {
        "id": "YFPTjeUFNJ1L"
      },
      "source": [
        "\n",
        "These functions support the Minmax algorithm by evaluating nodes, checking for terminal conditions, and generating child nodes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "KOA6MMpHMEFt",
      "metadata": {
        "id": "KOA6MMpHMEFt"
      },
      "outputs": [],
      "source": [
        "def is_terminal_node(node):\n",
        "    # Check if a node represents a terminal point (end of path).\n",
        "    # Example: Returns True if all regions in the path have been allocated resources.\n",
        "    allocated_regions = [region for region, _ in node]\n",
        "    return len(allocated_regions) == len(path)\n",
        "\n",
        "def evaluate_node(node):\n",
        "    # Calculate the utility value of a node.\n",
        "    # Example: Summing up the units assigned to each region for simplicity.\n",
        "    utility = 0\n",
        "    for region, units in node:\n",
        "        # Example logic: Calculate utility based on effectiveness of allocated units.\n",
        "        # For instance, each unit may reduce fire damage by 10%; add benefits accordingly.\n",
        "        utility += units * 10  # Placeholder: Adjust based on the actual impact.\n",
        "    return utility\n",
        "\n",
        "def generate_children(node):\n",
        "    # Generate child nodes for a given node.\n",
        "    current_level = len(node)\n",
        "    if current_level >= len(path):\n",
        "        return []  # No more children if at the end of the path.\n",
        "\n",
        "    children = []\n",
        "    remaining_units = total_units - sum(units for _, units in node)\n",
        "    if remaining_units > 0:\n",
        "        for units in range(1, remaining_units + 1):\n",
        "            child = node + [(path[current_level], units)]\n",
        "            children.append(child)\n",
        "    return children"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6hHWH9uKXvh",
      "metadata": {
        "id": "c6hHWH9uKXvh"
      },
      "source": [
        "#### Step 5: Execute the Minmax Algorithm\n",
        "Finally, we run the Minmax function on the generated game tree to identify the optimal allocation strategy for the Max player."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "DVWeTF7wKdQe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVWeTF7wKdQe",
        "outputId": "66429d58-e714-476a-87cc-35d0a9d06185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best allocation strategy value: 60\n"
          ]
        }
      ],
      "source": [
        "best_value = minmax(game_tree[0], depth=3, is_max_player=True, alpha=float('-inf'), beta=float('inf'))\n",
        "print(\"Best allocation strategy value:\", best_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "G6dHaftFNP25",
      "metadata": {
        "id": "G6dHaftFNP25"
      },
      "source": [
        "### Results and Interpretation\n",
        "The optimal allocation strategy yielded a total utility score of 60, representing the maximum effectiveness achieved through the optimal distribution of resources across the regions. This score reflects the cumulative impact of the units allocated, based on their contribution to reducing fire damage or clearing road blockages. If the utility calculation incorporates these factors, this result confirms that the algorithm successfully identified a resource allocation strategy that maximizes the effectiveness of response efforts.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b0448e2",
      "metadata": {
        "id": "7b0448e2"
      },
      "source": [
        "## Task 4: Game Theory for Multi-Agent Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5c85a2a",
      "metadata": {
        "id": "b5c85a2a"
      },
      "source": [
        "report your design here. A step follows a piece of code is preferred.\n",
        "\n",
        "_hints:_ You can develop payoff matrices to determine optimal parameter values in this project by selecting the best value from a list of candidate options based on your design. A common approach is to evaluate parameter candidates by testing a range of values in defined steps. For example, the `parameter` can take values from the set `{0, 1, 2, 3, 4}` in steps of 1. Then, the set is a list of actions for one player in game theory. Accordingly, you need to initial a all-zero payoff matrix to compute its payoff values. `payoffs = [[0 for _ in range(len(action_payer1))] for _ in range(len(action_payer2))]`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m3UhqhRgPzGs",
      "metadata": {
        "id": "m3UhqhRgPzGs"
      },
      "source": [
        "#### Step 1: Develop Payoff Matrices\n",
        "To apply game theory in the context of multi-agent systems, we first need to set up payoff matrices representing the strategies of two players. Each player has a set of candidate strategies they can choose from. The objective is to evaluate these payoffs and identify optimal strategies based on the matrix values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "b5b0b2eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5b0b2eb",
        "outputId": "c84d3b8d-e05b-4164-cab3-7d2424a1c24a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized Payoff Matrix:\n",
            "[0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "def initialize_payoff_matrix(actions_player1, actions_player2):\n",
        "    # Create an empty payoff matrix with zero values.\n",
        "    payoffs = [[0 for _ in range(len(actions_player1))] for _ in range(len(actions_player2))]\n",
        "    return payoffs\n",
        "\n",
        "# Example actions for both players\n",
        "actions_player1 = [0, 1, 2, 3, 4]  # Example strategy values for Player 1\n",
        "actions_player2 = [0, 1, 2, 3, 4]  # Example strategy values for Player 2\n",
        "\n",
        "# Initialize the payoff matrix\n",
        "payoff_matrix = initialize_payoff_matrix(actions_player1, actions_player2)\n",
        "print(\"Initialized Payoff Matrix:\")\n",
        "for row in payoff_matrix:\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hIdJ3YlPQPU-",
      "metadata": {
        "id": "hIdJ3YlPQPU-"
      },
      "source": [
        "#### Step 2: Populate the Payoff Matrix\n",
        "In this step, we calculate the payoffs for each possible combination of actions by simulating the outcomes based on the chosen parameter values. The matrix is populated by assessing the effectiveness of each action combination.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "NmkVNn0EQRbz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmkVNn0EQRbz",
        "outputId": "e04b68a5-76fd-40b3-d90f-655fccdea1cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Populated Payoff Matrix:\n",
            "[0, 0, 0, 0, 0]\n",
            "[0, 1, 2, 3, 4]\n",
            "[0, 2, 4, 6, 8]\n",
            "[0, 3, 6, 9, 12]\n",
            "[0, 4, 8, 12, 16]\n"
          ]
        }
      ],
      "source": [
        "def evaluate_payoff(action1, action2):\n",
        "    # Calculate the payoff for a specific pair of actions.\n",
        "    # Placeholder logic for payoff calculation; replace with actual evaluation.\n",
        "    return action1 * action2  # Example: simple product of actions for demonstration\n",
        "\n",
        "def populate_payoff_matrix(actions_player1, actions_player2):\n",
        "    # Fill in the payoff matrix with calculated payoff values.\n",
        "    payoffs = initialize_payoff_matrix(actions_player1, actions_player2)\n",
        "    for i, action1 in enumerate(actions_player1):\n",
        "        for j, action2 in enumerate(actions_player2):\n",
        "            payoffs[i][j] = evaluate_payoff(action1, action2)\n",
        "    return payoffs\n",
        "\n",
        "# Populate the payoff matrix with computed payoffs\n",
        "payoff_matrix = populate_payoff_matrix(actions_player1, actions_player2)\n",
        "print(\"Populated Payoff Matrix:\")\n",
        "for row in payoff_matrix:\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Mt9PYYo7QraP",
      "metadata": {
        "id": "Mt9PYYo7QraP"
      },
      "source": [
        "#### Step 3: Determine Optimal Strategies\n",
        "With the payoff matrix fully populated, we can analyze it to identify optimal strategies for each player. This involves finding the Nash equilibrium, where neither player has an incentive to change their strategy unilaterally, or exploring dominant strategies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "oarAgl7MQtJA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oarAgl7MQtJA",
        "outputId": "4960fbae-ec32-49a8-ef5a-32711ba93f1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nash Equilibrium: [(0, 0), (4, 4)]\n"
          ]
        }
      ],
      "source": [
        "def find_nash_equilibrium(payoff_matrix):\n",
        "# Identify Nash equilibria in the payoff matrix.\n",
        "    nash_equilibria = []\n",
        "    for i in range(len(payoff_matrix)):\n",
        "        for j in range(len(payoff_matrix[i])):\n",
        "            row_max = max(payoff_matrix[i])  # Maximum in the current row\n",
        "            col_max = max(row[j] for row in payoff_matrix)  # Maximum in the current column\n",
        "            if payoff_matrix[i][j] == row_max and payoff_matrix[i][j] == col_max:\n",
        "                nash_equilibria.append((i, j))  # Nash equilibrium point\n",
        "    return nash_equilibria\n",
        "\n",
        "# Find and print Nash equilibria in the payoff matrix\n",
        "nash_equilibria = find_nash_equilibrium(payoff_matrix)\n",
        "print(\"Nash Equilibrium:\", nash_equilibria)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hfLLSz0LRImD",
      "metadata": {
        "id": "hfLLSz0LRImD"
      },
      "source": [
        "### Results and Interpretation\n",
        "The Nash equilibria identified in the payoff matrix are located at positions (0,0) and (4,4).\n",
        "\n",
        "(0, 0):\n",
        "This equilibrium corresponds to a strategy where both actions_player1 and actions_player2 select their first action (indexed as 0).\n",
        "At this point, neither player can improve their outcome by changing their strategy unilaterally, making it an equilibrium.\n",
        "\n",
        "(4, 4):\n",
        "This equilibrium represents a scenario where both actions_player1 and actions_player2 choose their final action (indexed as 4).\n",
        "Here, neither player has any incentive to deviate, establishing another stable equilibrium.\n",
        "\n",
        "Conclusion: The Nash equilibria indicate that the optimal strategies for both players occur at positions where neither benefits from altering their choice independently. This analysis provides insight into the most effective parameter values for coordinating actions among agents, promoting balanced strategies that account for potential adversarial responses or influences from other agents."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a42b2d7",
      "metadata": {
        "id": "6a42b2d7"
      },
      "source": [
        "## Task 5: Bayesian Networks for Uncertain Inferences"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bc1b99e",
      "metadata": {
        "id": "5bc1b99e"
      },
      "source": [
        "report your design here. A step follows a piece of code is preferred.\n",
        "\n",
        "_hints:_ Given a rescue scenario and a specific path, what are the variables to consider? Based on the available information, you will need to construct the topology of a Bayesian network, identifying dependencies between the variables, and then calculate the Conditional Probability Tables (CPTs) for each node in the network. Finally, make the inference contribute to the rescue optimization."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8uLW1Y-cRlcy",
      "metadata": {
        "id": "8uLW1Y-cRlcy"
      },
      "source": [
        "#### Step 1: Identify Variables and Dependencies\n",
        "\n",
        "In a rescue scenario, the Bayesian network should represent relevant variables and their dependencies. Key variables to consider include:\n",
        "\n",
        "FireSpread: The probability of fire spreading to neighboring regions.\n",
        "RoadBlockage: The likelihood of roads being blocked due to aftershocks.\n",
        "RescueSuccess: The probability of a successful rescue operation.\n",
        "UnitAllocation: The number of units assigned to a region.\n",
        "\n",
        "Dependencies:\n",
        "\n",
        "FireSpread depends on factors like current fire intensity and weather conditions.\n",
        "RoadBlockage is influenced by the occurrence of aftershocks.\n",
        "RescueSuccess is affected by UnitAllocation, FireSpread, and RoadBlockage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "14d8a942",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "14d8a942",
        "outputId": "e395c359-1f5e-4ff8-9c8c-2e3d39320fbc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the structure of the Bayesian network\n",
        "graph = nx.DiGraph()\n",
        "graph.add_edges_from([\n",
        "    (\"FireSpread\", \"RescueSuccess\"),\n",
        "    (\"RoadBlockage\", \"RescueSuccess\"),\n",
        "    (\"UnitAllocation\", \"RescueSuccess\")\n",
        "])\n",
        "\n",
        "# Visualize the Bayesian network structure\n",
        "plt.figure(figsize=(8, 6))\n",
        "nx.draw_networkx(graph, with_labels=True, node_color='lightblue', edge_color='black')\n",
        "plt.title(\"Bayesian Network Structure\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RX-AICZOSCCr",
      "metadata": {
        "id": "RX-AICZOSCCr"
      },
      "source": [
        "#### Step 2: Construct Conditional Probability Tables (CPTs)\n",
        "Constructing CPTs involves defining the conditional probabilities for each node in the network.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RSzZZCXtSDqh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSzZZCXtSDqh",
        "outputId": "7f5c1ecc-8454-4898-c8b9-3b3fab1a39e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPT for Fire Spread:\n",
            "+---------------+-----+\n",
            "| FireSpread(0) | 0.7 |\n",
            "+---------------+-----+\n",
            "| FireSpread(1) | 0.3 |\n",
            "+---------------+-----+\n",
            "\n",
            "CPT for Road Blockage:\n",
            "+-----------------+-----+\n",
            "| RoadBlockage(0) | 0.8 |\n",
            "+-----------------+-----+\n",
            "| RoadBlockage(1) | 0.2 |\n",
            "+-----------------+-----+\n",
            "\n",
            "CPT for Unit Allocation:\n",
            "+-------------------+-----+\n",
            "| UnitAllocation(0) | 0.5 |\n",
            "+-------------------+-----+\n",
            "| UnitAllocation(1) | 0.5 |\n",
            "+-------------------+-----+\n",
            "\n",
            "CPT for Rescue Success:\n",
            "+------------------+-----+-------------------+\n",
            "| UnitAllocation   | ... | UnitAllocation(1) |\n",
            "+------------------+-----+-------------------+\n",
            "| FireSpread       | ... | FireSpread(1)     |\n",
            "+------------------+-----+-------------------+\n",
            "| RoadBlockage     | ... | RoadBlockage(1)   |\n",
            "+------------------+-----+-------------------+\n",
            "| RescueSuccess(0) | ... | 0.3               |\n",
            "+------------------+-----+-------------------+\n",
            "| RescueSuccess(1) | ... | 0.7               |\n",
            "+------------------+-----+-------------------+\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from pgmpy.factors.discrete import TabularCPD\n",
        "\n",
        "# Example CPTs for the Bayesian network\n",
        "cpt_fire_spread = TabularCPD(\n",
        "    variable='FireSpread',\n",
        "    variable_card=2,\n",
        "    values=[[0.7], [0.3]]  # Probabilities for 'Low' and 'High'\n",
        ")\n",
        "\n",
        "cpt_road_blockage = TabularCPD(\n",
        "    variable='RoadBlockage',\n",
        "    variable_card=2,\n",
        "    values=[[0.8], [0.2]]  # Probabilities for 'No' and 'Yes'\n",
        ")\n",
        "\n",
        "cpt_unit_allocation = TabularCPD(\n",
        "    variable='UnitAllocation',\n",
        "    variable_card=2,\n",
        "    values=[[0.5], [0.5]]  # Probabilities for 'Low' and 'High'\n",
        ")\n",
        "\n",
        "cpt_rescue_success = TabularCPD(\n",
        "    variable='RescueSuccess',\n",
        "    variable_card=2,\n",
        "    values=[\n",
        "        [0.9, 0.6, 0.8, 0.5, 0.7, 0.4, 0.6, 0.3],  # Probability of success\n",
        "        [0.1, 0.4, 0.2, 0.5, 0.3, 0.6, 0.4, 0.7]   # Probability of failure (1 - success)\n",
        "    ],\n",
        "    evidence=['UnitAllocation', 'FireSpread', 'RoadBlockage'],\n",
        "    evidence_card=[2, 2, 2]  # Cardinalities of evidence variables\n",
        ")\n",
        "\n",
        "# Display the CPTs\n",
        "print(\"CPT for Fire Spread:\")\n",
        "print(cpt_fire_spread)\n",
        "print(\"\\nCPT for Road Blockage:\")\n",
        "print(cpt_road_blockage)\n",
        "print(\"\\nCPT for Unit Allocation:\")\n",
        "print(cpt_unit_allocation)\n",
        "print(\"\\nCPT for Rescue Success:\")\n",
        "print(cpt_rescue_success)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ASgoJkUIV691",
      "metadata": {
        "id": "ASgoJkUIV691"
      },
      "source": [
        "**Result**:\n",
        "The CPTs were successfully created and displayed, showing the conditional probabilities for each variable."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Uz9vIEkfSmLB",
      "metadata": {
        "id": "Uz9vIEkfSmLB"
      },
      "source": [
        "#### Step 3: Make Inferences Using the Bayesian Network\n",
        "Using the Bayesian network, we can infer the probability of a successful rescue operation under specific conditions. These inferences support optimal decision-making for rescue operations by assessing risks and aiding in resource allocation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n1T3eBLeSoXe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1T3eBLeSoXe",
        "outputId": "fb56f658-a48b-447a-e56f-91f43c064cba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Inference Result:\n",
            "+------------------+----------------------+\n",
            "| RescueSuccess    |   phi(RescueSuccess) |\n",
            "+==================+======================+\n",
            "| RescueSuccess(0) |               0.7000 |\n",
            "+------------------+----------------------+\n",
            "| RescueSuccess(1) |               0.3000 |\n",
            "+------------------+----------------------+\n"
          ]
        }
      ],
      "source": [
        "from pgmpy.models import BayesianNetwork\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "# Define the structure of the Bayesian network model\n",
        "model = BayesianNetwork([\n",
        "    (\"FireSpread\", \"RescueSuccess\"),\n",
        "    (\"RoadBlockage\", \"RescueSuccess\"),\n",
        "    (\"UnitAllocation\", \"RescueSuccess\")\n",
        "])\n",
        "\n",
        "# Add Conditional Probability Distributions (CPDs) to the model\n",
        "model.add_cpds(cpt_fire_spread, cpt_road_blockage, cpt_unit_allocation, cpt_rescue_success)\n",
        "\n",
        "# Validate the model structure\n",
        "assert model.check_model(), \"The model is not valid!\"\n",
        "\n",
        "# Set up inference with Variable Elimination\n",
        "inference = VariableElimination(model)\n",
        "\n",
        "# Perform inference with specific evidence values\n",
        "result = inference.query(variables=['RescueSuccess'], evidence={'FireSpread': 1, 'RoadBlockage': 0})\n",
        "\n",
        "print(\"\\nInference Result:\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EyA8O_TKVfNO",
      "metadata": {
        "id": "EyA8O_TKVfNO"
      },
      "source": [
        "### Results and Interpretation\n",
        "**Report**:\n",
        "\n",
        "The inference results indicate:\n",
        "\n",
        "**RescueSuccess(0):** The probability of an unsuccessful rescue operation is 70% (0.700).\n",
        "\n",
        "**RescueSuccess(1):** The probability of a successful rescue operation is 30% (0.300).\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "These probabilities suggest that, given the specified conditions—FireSpread set to high and RoadBlockage absent—the likelihood of a successful rescue is relatively low at 30%. This indicates that high fire spread considerably impacts the success rate of rescue operations. Understanding these probabilities enables more informed decision-making regarding resource allocation and strategic planning for rescue efforts.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "184c5e07",
      "metadata": {
        "id": "184c5e07"
      },
      "source": [
        "# Overall Running"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6697bf4",
      "metadata": {
        "id": "a6697bf4"
      },
      "source": [
        "You need to provide the overall rescure results by code running based on your overall design and breakdown task designs. It is preferred to put `functions` in the breakdown task above and execute them in the overall running here.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Nm2CKS_fWb39",
      "metadata": {
        "id": "Nm2CKS_fWb39"
      },
      "source": [
        "### Step 1: Run Genetic Algorithm for Path Optimization (Task 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "981c1a88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "981c1a88",
        "outputId": "ac360580-d92e-4dcc-a0bb-4b45d2887010"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best path found by Genetic Algorithm: ['R1', 'R4', 'R5', 'R2', 'R3', 'R1']\n"
          ]
        }
      ],
      "source": [
        "best_path = genetic_algorithm(initial_population, 20)\n",
        "print(\"Best path found by Genetic Algorithm:\", best_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "q7e7G0FFWl-x",
      "metadata": {
        "id": "q7e7G0FFWl-x"
      },
      "source": [
        "### Step 2: Simulate Multi-Agent Coordination with Ant Colony Optimization (Task 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X62LJeh7Wmpm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X62LJeh7Wmpm",
        "outputId": "c4b97783-98c4-499f-d118-bf74ef21bf99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ACO Coordination Result: [['R1', 'R5', 'R3', 'R2', 'R4', 'R1'], ['R1', 'R5', 'R4', 'R3', 'R2', 'R1'], ['R1', 'R5', 'R4', 'R3', 'R2', 'R1'], ['R1', 'R5', 'R4', 'R3', 'R2', 'R1'], ['R1', 'R5', 'R4', 'R3', 'R2', 'R1']]\n"
          ]
        }
      ],
      "source": [
        "def simulate_aco_for_rescue(start_region, num_agents):\n",
        "    # Initial setup of pheromone levels, agents, and paths\n",
        "    pheromone_levels = {edge: 1.0 for edge in distances.keys()}  # Initialize pheromone levels\n",
        "    agents_paths = []\n",
        "    exploration_factor = 0.3  # Factor to introduce randomness for exploration\n",
        "\n",
        "    # Simulate agent path selection and pheromone updates\n",
        "    for agent in range(num_agents):\n",
        "        path = simulate_agent_path(start_region, pheromone_levels, exploration_factor)\n",
        "        agents_paths.append(path)\n",
        "        deposit_pheromones(path)\n",
        "        evaporate_pheromones()\n",
        "\n",
        "    return agents_paths\n",
        "\n",
        "# Example run of the ACO algorithm\n",
        "aco_result = simulate_aco_for_rescue(start_region, num_agents)\n",
        "print(\"ACO Coordination Result:\", aco_result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AkSRWUPTWujm",
      "metadata": {
        "id": "AkSRWUPTWujm"
      },
      "source": [
        "### Step 3: Apply the Minmax Algorithm with Alpha-Beta Pruning (Task 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TeoLk3Z4WvDu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeoLk3Z4WvDu",
        "outputId": "7dcb73c8-da21-4d52-b528-4c8e2c49a0a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best allocation strategy value from Minmax Algorithm: 60\n"
          ]
        }
      ],
      "source": [
        "optimal_strategy_value = minmax(game_tree[0], depth=3, is_max_player=True, alpha=float('-inf'), beta=float('inf'))\n",
        "print(\"Best allocation strategy value from Minmax Algorithm:\", optimal_strategy_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jcFhG09QfPFD",
      "metadata": {
        "id": "jcFhG09QfPFD"
      },
      "source": [
        "### Step 4: Use Game Theory to Identify Optimal Strategies (Task 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VvAFZaunfPmA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvAFZaunfPmA",
        "outputId": "ce81dde9-3de4-4c83-845f-3f055939c51f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nash Equilibria found: [(0, 0), (4, 4)]\n"
          ]
        }
      ],
      "source": [
        "nash_equilibria = find_nash_equilibrium(payoff_matrix)\n",
        "print(\"Nash Equilibria found:\", nash_equilibria)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57_3hiA_fUfR",
      "metadata": {
        "id": "57_3hiA_fUfR"
      },
      "source": [
        "### Step 5: Integrate Bayesian Network for Uncertain Inferences (Task 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "II3spEDffVBH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II3spEDffVBH",
        "outputId": "7b672b04-edd9-468e-e258-899af353c41a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Overall Inference Result for Rescue Success:\n",
            "+------------------+----------------------+\n",
            "| RescueSuccess    |   phi(RescueSuccess) |\n",
            "+==================+======================+\n",
            "| RescueSuccess(0) |               0.7000 |\n",
            "+------------------+----------------------+\n",
            "| RescueSuccess(1) |               0.3000 |\n",
            "+------------------+----------------------+\n"
          ]
        }
      ],
      "source": [
        "# Define the Bayesian network model\n",
        "model = BayesianNetwork([(\"FireSpread\", \"RescueSuccess\"), (\"RoadBlockage\", \"RescueSuccess\"), (\"UnitAllocation\", \"RescueSuccess\")])\n",
        "\n",
        "# Add CPDs to the model\n",
        "model.add_cpds(cpd_fire_spread, cpd_road_blockage, cpd_unit_allocation, cpd_rescue_success)\n",
        "\n",
        "# Check if the model is valid\n",
        "assert model.check_model(), \"The model is not valid!\"\n",
        "\n",
        "# Perform inference\n",
        "inference = VariableElimination(model)\n",
        "result = inference.query(variables=['RescueSuccess'], evidence={'FireSpread': 1, 'RoadBlockage': 0})\n",
        "\n",
        "print(\"\\nOverall Inference Result for Rescue Success:\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b121817",
      "metadata": {
        "id": "7b121817"
      },
      "source": [
        "# Conclustion and Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09b42ef6",
      "metadata": {
        "id": "09b42ef6"
      },
      "source": [
        "The approach integrates all components into a unified rescue strategy that optimizes routing, coordinates responders, distributes resources effectively, and assesses risks using probabilistic methods. This comprehensive, flexible strategy is designed to adapt well to various disaster scenarios.\n",
        "\n",
        "***Advantages of the Integrated Approach:***\n",
        "\n",
        "**Comprehensive Strategy:** By leveraging diverse algorithms and techniques, this approach delivers a balanced blend of deterministic and probabilistic decision-making.\n",
        "\n",
        "**Flexibility:** Its modular setup enables each component to be adjusted or expanded to handle more complex situations.\n",
        "\n",
        "**Resilience:** The inclusion of game theory and Bayesian inference strengthens decision-making by factoring in uncertainties and adversarial elements.\n",
        "\n",
        "***Potential Drawbacks:***\n",
        "\n",
        "**High Computational Demand:** Running multiple advanced algorithms either sequentially or concurrently can significantly increase computational requirements and processing time.\n",
        "\n",
        "**Dependence on Parameter Optimization:** The success of certain methods, like genetic algorithms and ant colony optimization, relies on fine-tuning hyperparameters for optimal results.\n",
        "\n",
        "**Real-World Modeling Assumptions:** Some of the model’s assumptions may not fully capture the complexity of real-life disaster environments.\n",
        "Opportunities for Enhancement:\n",
        "\n",
        "**Improved Real-Time Responsiveness:** Integrating live data to enable dynamic adjustments in strategy during rescue operations.\n",
        "\n",
        "**Advances with Machine Learning:** Implementing reinforcement learning to refine decision-making over time based on historical data.\n",
        "\n",
        "**Enhanced Resource Allocation:** Further developing resource distribution strategies using multi-objective optimization approaches.\n",
        "\n",
        "**These enhancements could expand the approach's effectiveness and make it more versatile for various disaster management and emergency response scenarios.**\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
