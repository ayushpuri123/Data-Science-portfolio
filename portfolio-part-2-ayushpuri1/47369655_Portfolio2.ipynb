{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Z88FfJc9lA_T",
   "metadata": {
    "id": "Z88FfJc9lA_T"
   },
   "source": [
    "## Analysis of an E-commerce Dataset Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hoq0NwA9lA_V",
   "metadata": {
    "id": "hoq0NwA9lA_V"
   },
   "source": [
    "The goal of the second analysis task is to train linear regression models to predict users' ratings towards items. This involves a standard Data Science workflow: exploring data, building models, making predictions, and evaluating results. In this task, we will explore the impacts of feature selections and different sizes of training/testing data on the model performance. We will use another cleaned combined e-commerce sub-dataset that **is different from** the one in “Analysis of an E-commerce Dataset” task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fd3NU_lA_W",
   "metadata": {
    "id": "f9fd3NU_lA_W"
   },
   "source": [
    "### Import Cleaned E-commerce Dataset\n",
    "The csv file named 'cleaned_ecommerce_dataset.csv' is provided. You may need to use the Pandas method, i.e., `read_csv`, for reading it. After that, please print out its total length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "PJrb2gtAlA_W",
   "metadata": {
    "id": "PJrb2gtAlA_W"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>review</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>gender</th>\n",
       "      <th>category</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>user_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4081</td>\n",
       "      <td>71900</td>\n",
       "      <td>Not always McCrap</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>41</td>\n",
       "      <td>30.74</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4081</td>\n",
       "      <td>72000</td>\n",
       "      <td>I dropped the chalupa even before he told me to</td>\n",
       "      <td>Taco Bell</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>74</td>\n",
       "      <td>108.30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4081</td>\n",
       "      <td>72000</td>\n",
       "      <td>The Wonderful World of Wendy</td>\n",
       "      <td>Wendy's</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>84</td>\n",
       "      <td>69.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4081</td>\n",
       "      <td>100399</td>\n",
       "      <td>They actually did it</td>\n",
       "      <td>South Park: Bigger, Longer &amp; Uncut</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>68</td>\n",
       "      <td>143.11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4081</td>\n",
       "      <td>100399</td>\n",
       "      <td>Hey! Gimme some pie!</td>\n",
       "      <td>American Pie</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>6</td>\n",
       "      <td>117.89</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>2445</td>\n",
       "      <td>22000</td>\n",
       "      <td>Great movie!</td>\n",
       "      <td>Austin Powers: The Spy Who Shagged Me</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>9</td>\n",
       "      <td>111.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681</th>\n",
       "      <td>2445</td>\n",
       "      <td>30700</td>\n",
       "      <td>Good food!</td>\n",
       "      <td>Outback Steakhouse</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>50</td>\n",
       "      <td>25.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682</th>\n",
       "      <td>2445</td>\n",
       "      <td>61500</td>\n",
       "      <td>Great movie!</td>\n",
       "      <td>Fight Club</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>26</td>\n",
       "      <td>97.53</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683</th>\n",
       "      <td>2445</td>\n",
       "      <td>100500</td>\n",
       "      <td>Awesome Game.</td>\n",
       "      <td>The Sims 2: Open for Business for Windows</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Games</td>\n",
       "      <td>79</td>\n",
       "      <td>27.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2684</th>\n",
       "      <td>2445</td>\n",
       "      <td>101400</td>\n",
       "      <td>Great Service.</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Personal Finance</td>\n",
       "      <td>52</td>\n",
       "      <td>38.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2685 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId  timestamp                                           review  \\\n",
       "0       4081      71900                                Not always McCrap   \n",
       "1       4081      72000  I dropped the chalupa even before he told me to   \n",
       "2       4081      72000                     The Wonderful World of Wendy   \n",
       "3       4081     100399                             They actually did it   \n",
       "4       4081     100399                             Hey! Gimme some pie!   \n",
       "...      ...        ...                                              ...   \n",
       "2680    2445      22000                                     Great movie!   \n",
       "2681    2445      30700                                       Good food!   \n",
       "2682    2445      61500                                     Great movie!   \n",
       "2683    2445     100500                                    Awesome Game.   \n",
       "2684    2445     101400                                   Great Service.   \n",
       "\n",
       "                                           item  rating  helpfulness gender  \\\n",
       "0                                    McDonald's     4.0          3.0      M   \n",
       "1                                     Taco Bell     1.0          4.0      M   \n",
       "2                                       Wendy's     5.0          4.0      M   \n",
       "3            South Park: Bigger, Longer & Uncut     5.0          3.0      M   \n",
       "4                                  American Pie     3.0          3.0      M   \n",
       "...                                         ...     ...          ...    ...   \n",
       "2680      Austin Powers: The Spy Who Shagged Me     5.0          3.0      M   \n",
       "2681                         Outback Steakhouse     5.0          3.0      M   \n",
       "2682                                 Fight Club     5.0          3.0      M   \n",
       "2683  The Sims 2: Open for Business for Windows     5.0          4.0      M   \n",
       "2684                                     PayPal     5.0          3.0      M   \n",
       "\n",
       "                   category  item_id  item_price  user_city  \n",
       "0     Restaurants & Gourmet       41       30.74          4  \n",
       "1     Restaurants & Gourmet       74      108.30          4  \n",
       "2     Restaurants & Gourmet       84       69.00          4  \n",
       "3                    Movies       68      143.11          4  \n",
       "4                    Movies        6      117.89          4  \n",
       "...                     ...      ...         ...        ...  \n",
       "2680                 Movies        9      111.00          5  \n",
       "2681  Restaurants & Gourmet       50       25.00          5  \n",
       "2682                 Movies       26       97.53          5  \n",
       "2683                  Games       79       27.00          5  \n",
       "2684       Personal Finance       52       38.00          5  \n",
       "\n",
       "[2685 rows x 11 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "data=pd.read_csv('cleaned_ecommerce_dataset.csv')\n",
    "len(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aqbuU6rglA_X",
   "metadata": {
    "id": "aqbuU6rglA_X"
   },
   "source": [
    "### Explore the Dataset\n",
    "\n",
    "* Use the methods, i.e., `head()` and `info()`, to have a rough picture about the data, e.g., how many columns, and the data types of each column.\n",
    "* As our goal is to predict ratings given other columns, please get the correlations between helpfulness/gender/category/review and rating by using the `corr()` method.\n",
    "* To get the correlations between different features, you may need to first convert the categorical features (i.e., gender, category and review) into numerial values. For doing this, you may need to import `OrdinalEncoder` from `sklearn.preprocessing` (refer to the useful exmaples [here](https://pbpython.com/categorical-encoding.html))\n",
    "* Please provide ___necessary explanations/analysis___ on the correlations, and figure out which are the ___most___ and ___least___ corrleated features regarding rating. Try to ___discuss___ how the correlation will affect the final prediction results, if we use these features to train a regression model for rating prediction. In what follows, we will conduct experiments to verify your hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "W3PImHiElA_X",
   "metadata": {
    "id": "W3PImHiElA_X"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>review</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>gender</th>\n",
       "      <th>category</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>user_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4081</td>\n",
       "      <td>71900</td>\n",
       "      <td>Not always McCrap</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>41</td>\n",
       "      <td>30.74</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4081</td>\n",
       "      <td>72000</td>\n",
       "      <td>I dropped the chalupa even before he told me to</td>\n",
       "      <td>Taco Bell</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>74</td>\n",
       "      <td>108.30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4081</td>\n",
       "      <td>72000</td>\n",
       "      <td>The Wonderful World of Wendy</td>\n",
       "      <td>Wendy's</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>84</td>\n",
       "      <td>69.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4081</td>\n",
       "      <td>100399</td>\n",
       "      <td>They actually did it</td>\n",
       "      <td>South Park: Bigger, Longer &amp; Uncut</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>68</td>\n",
       "      <td>143.11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4081</td>\n",
       "      <td>100399</td>\n",
       "      <td>Hey! Gimme some pie!</td>\n",
       "      <td>American Pie</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>6</td>\n",
       "      <td>117.89</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4081</td>\n",
       "      <td>100399</td>\n",
       "      <td>Good for sci-fi</td>\n",
       "      <td>Matrix</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>40</td>\n",
       "      <td>24.51</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4081</td>\n",
       "      <td>100399</td>\n",
       "      <td>Scary? you bet!</td>\n",
       "      <td>Blair Witch Project</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>12</td>\n",
       "      <td>44.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4081</td>\n",
       "      <td>101899</td>\n",
       "      <td>Fox - the 4th basic channel</td>\n",
       "      <td>FOX</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Media</td>\n",
       "      <td>25</td>\n",
       "      <td>80.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4081</td>\n",
       "      <td>112099</td>\n",
       "      <td>Amen!</td>\n",
       "      <td>Dogma</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>22</td>\n",
       "      <td>87.59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4081</td>\n",
       "      <td>122899</td>\n",
       "      <td>mama mia!</td>\n",
       "      <td>Olive Garden</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>49</td>\n",
       "      <td>32.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  timestamp                                           review  \\\n",
       "0    4081      71900                                Not always McCrap   \n",
       "1    4081      72000  I dropped the chalupa even before he told me to   \n",
       "2    4081      72000                     The Wonderful World of Wendy   \n",
       "3    4081     100399                             They actually did it   \n",
       "4    4081     100399                             Hey! Gimme some pie!   \n",
       "5    4081     100399                                  Good for sci-fi   \n",
       "6    4081     100399                                  Scary? you bet!   \n",
       "7    4081     101899                      Fox - the 4th basic channel   \n",
       "8    4081     112099                                            Amen!   \n",
       "9    4081     122899                                        mama mia!   \n",
       "\n",
       "                                 item  rating  helpfulness gender  \\\n",
       "0                          McDonald's     4.0          3.0      M   \n",
       "1                           Taco Bell     1.0          4.0      M   \n",
       "2                             Wendy's     5.0          4.0      M   \n",
       "3  South Park: Bigger, Longer & Uncut     5.0          3.0      M   \n",
       "4                        American Pie     3.0          3.0      M   \n",
       "5                              Matrix     3.0          3.0      M   \n",
       "6                 Blair Witch Project     4.0          3.0      M   \n",
       "7                                 FOX     4.0          4.0      M   \n",
       "8                               Dogma     4.0          3.0      M   \n",
       "9                        Olive Garden     4.0          3.0      M   \n",
       "\n",
       "                category  item_id  item_price  user_city  \n",
       "0  Restaurants & Gourmet       41       30.74          4  \n",
       "1  Restaurants & Gourmet       74      108.30          4  \n",
       "2  Restaurants & Gourmet       84       69.00          4  \n",
       "3                 Movies       68      143.11          4  \n",
       "4                 Movies        6      117.89          4  \n",
       "5                 Movies       40       24.51          4  \n",
       "6                 Movies       12       44.00          4  \n",
       "7                  Media       25       80.00          4  \n",
       "8                 Movies       22       87.59          4  \n",
       "9  Restaurants & Gourmet       49       32.00          4  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the First 10 rows of dataset\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cce5c455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2685 entries, 0 to 2684\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   userId       2685 non-null   int64  \n",
      " 1   timestamp    2685 non-null   int64  \n",
      " 2   review       2685 non-null   object \n",
      " 3   item         2685 non-null   object \n",
      " 4   rating       2685 non-null   float64\n",
      " 5   helpfulness  2685 non-null   float64\n",
      " 6   gender       2685 non-null   object \n",
      " 7   category     2685 non-null   object \n",
      " 8   item_id      2685 non-null   int64  \n",
      " 9   item_price   2685 non-null   float64\n",
      " 10  user_city    2685 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(4)\n",
      "memory usage: 230.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#Displaying information about the data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58cc016b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>helpfulness</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <td>-0.007523</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             helpfulness    rating\n",
       "helpfulness     1.000000 -0.007523\n",
       "rating         -0.007523  1.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the correlation between 'helpfulness' and 'rating'\n",
    "correlation1 = data[['helpfulness','rating']].corr()\n",
    "\n",
    "# Print the correlation coefficient\n",
    "correlation1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c28f5e",
   "metadata": {},
   "source": [
    "The correlation between helpfulness and rating is negative and very weak, almost no linear relationship is being observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6e22fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>user_city</th>\n",
       "      <th>gender</th>\n",
       "      <th>category</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4081</td>\n",
       "      <td>71900</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41</td>\n",
       "      <td>30.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1618.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4081</td>\n",
       "      <td>72000</td>\n",
       "      <td>Taco Bell</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>74</td>\n",
       "      <td>108.30</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4081</td>\n",
       "      <td>72000</td>\n",
       "      <td>Wendy's</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84</td>\n",
       "      <td>69.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4081</td>\n",
       "      <td>100399</td>\n",
       "      <td>South Park: Bigger, Longer &amp; Uncut</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68</td>\n",
       "      <td>143.11</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4081</td>\n",
       "      <td>100399</td>\n",
       "      <td>American Pie</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>117.89</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1033.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>2445</td>\n",
       "      <td>22000</td>\n",
       "      <td>Austin Powers: The Spy Who Shagged Me</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9</td>\n",
       "      <td>111.00</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>968.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681</th>\n",
       "      <td>2445</td>\n",
       "      <td>30700</td>\n",
       "      <td>Outback Steakhouse</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50</td>\n",
       "      <td>25.00</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682</th>\n",
       "      <td>2445</td>\n",
       "      <td>61500</td>\n",
       "      <td>Fight Club</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26</td>\n",
       "      <td>97.53</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>968.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683</th>\n",
       "      <td>2445</td>\n",
       "      <td>100500</td>\n",
       "      <td>The Sims 2: Open for Business for Windows</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79</td>\n",
       "      <td>27.00</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2684</th>\n",
       "      <td>2445</td>\n",
       "      <td>101400</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52</td>\n",
       "      <td>38.00</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>959.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2685 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId  timestamp                                       item  rating  \\\n",
       "0       4081      71900                                 McDonald's     4.0   \n",
       "1       4081      72000                                  Taco Bell     1.0   \n",
       "2       4081      72000                                    Wendy's     5.0   \n",
       "3       4081     100399         South Park: Bigger, Longer & Uncut     5.0   \n",
       "4       4081     100399                               American Pie     3.0   \n",
       "...      ...        ...                                        ...     ...   \n",
       "2680    2445      22000      Austin Powers: The Spy Who Shagged Me     5.0   \n",
       "2681    2445      30700                         Outback Steakhouse     5.0   \n",
       "2682    2445      61500                                 Fight Club     5.0   \n",
       "2683    2445     100500  The Sims 2: Open for Business for Windows     5.0   \n",
       "2684    2445     101400                                     PayPal     5.0   \n",
       "\n",
       "      helpfulness  item_id  item_price  user_city  gender  category  review  \n",
       "0             3.0       41       30.74          4     1.0       8.0  1618.0  \n",
       "1             4.0       74      108.30          4     1.0       8.0  1125.0  \n",
       "2             4.0       84       69.00          4     1.0       8.0  2185.0  \n",
       "3             3.0       68      143.11          4     1.0       5.0  2243.0  \n",
       "4             3.0        6      117.89          4     1.0       5.0  1033.0  \n",
       "...           ...      ...         ...        ...     ...       ...     ...  \n",
       "2680          3.0        9      111.00          5     1.0       5.0   968.0  \n",
       "2681          3.0       50       25.00          5     1.0       8.0   920.0  \n",
       "2682          3.0       26       97.53          5     1.0       5.0   968.0  \n",
       "2683          4.0       79       27.00          5     1.0       1.0   372.0  \n",
       "2684          3.0       52       38.00          5     1.0       7.0   959.0  \n",
       "\n",
       "[2685 rows x 11 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# Convert categorical columns to numerical values\n",
    "categorical_columns = ['gender', 'category', 'review']\n",
    "encoded_values = encoder.fit_transform(data[categorical_columns])\n",
    "data_encoded = pd.DataFrame(encoded_values, columns=categorical_columns)\n",
    "data_numeric = pd.concat([data.drop(categorical_columns, axis=1), data_encoded], axis=1)\n",
    "\n",
    "data_numeric\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52c62f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>review</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.036118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <td>-0.036118</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          review    rating\n",
       "review  1.000000 -0.036118\n",
       "rating -0.036118  1.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correlation for Review and Rating\n",
    "correlation2 =data_numeric[['review','rating']].corr()\n",
    "correlation2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855c666b",
   "metadata": {},
   "source": [
    "The correlation between helpfulness and rating is negative and very weak, almost no linear relationship is being observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e114dc7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.034337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <td>-0.034337</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          gender    rating\n",
       "gender  1.000000 -0.034337\n",
       "rating -0.034337  1.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation3 =data_numeric[['gender','rating']].corr()\n",
    "correlation3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7832cbf",
   "metadata": {},
   "source": [
    "The correlation between helpfulness and rating is negative and very weak, almost no linear relationship is being observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c387b945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.163158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <td>-0.163158</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          category    rating\n",
       "category  1.000000 -0.163158\n",
       "rating   -0.163158  1.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation4 =data_numeric[['category','rating']].corr()\n",
    "correlation4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddff434",
   "metadata": {},
   "source": [
    "Moderate linear relationshiop is being displayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df59817c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Split Training and Testing Data\n",
    "* Machine learning models are trained to help make predictions for the future. Normally, we need to randomly split the dataset into training and testing sets, where we use the training set to train the model, and then leverage the well-trained model to make predictions on the testing set.\n",
    "* To further investigate whether the size of the training/testing data affects the model performance, please random split the data into training and testing sets with different sizes:\n",
    "    * Case 1: training data containing 10% of the entire data;\n",
    "    * Case 2: training data containing 90% of the entire data.\n",
    "* Print the shape of training and testing sets in the two cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "JIDMig9blA_Y",
   "metadata": {
    "id": "JIDMig9blA_Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Case 1: (268, 11) (2417, 11)\n",
      "Shape Of Case 2: (2416, 11) (269, 11)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(data_numeric, test_size=0.9,random_state=142) #10% for test\n",
    "print('Shape of Case 1:', X_train.shape, X_test.shape)\n",
    "y_train, y_test = train_test_split(data_numeric, test_size=0.1,random_state=142,) #90% for test\n",
    "print('Shape Of Case 2:', y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DjSsgT0BlA_Y",
   "metadata": {
    "id": "DjSsgT0BlA_Y"
   },
   "source": [
    "### Train Linear Regression Models with Feature Selection under Cases 1 & 2\n",
    "* When training a machine learning model for prediction, we may need to select the most important/correlated input features for more accurate results.\n",
    "* To investigate whether feature selection affects the model performance, please select two most correlated features and two least correlated features regarding rating, respectively.\n",
    "* Train four linear regression models by following the conditions:\n",
    "    - (model-a) using the training/testing data in case 1 with two most correlated input features\n",
    "    - (model-b) using the training/testing data in case 1 with two least correlated input features\n",
    "    - (model-c) using the training/testing data in case 2 with two most correlated input features\n",
    "    - (model-d) using the training/testing data in case 2 with two least correlated input features\n",
    "* By doing this, we can verify the impacts of the size of traing/testing data on the model performance via comparing model-a and model-c (or model-b and model-d); meanwhile the impacts of feature selection can be validated via comparing model-a and model-b (or model-c and model-d).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8330dd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model A\n",
    "\n",
    "regA=linear_model.LinearRegression()\n",
    "XmodA=X_train[['category', 'review']]\n",
    "ymodA=X_train['rating']\n",
    "regA.fit(XmodA,ymodA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c451fa5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model B\n",
    "regB=linear_model.LinearRegression()\n",
    "Xmodb=X_train[['gender','helpfulness']]\n",
    "ymodb=X_train['rating']\n",
    "regB.fit(Xmodb,ymodb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8b8af29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model C\n",
    "regC=linear_model.LinearRegression()\n",
    "Xmodc=y_train[['category','review']]\n",
    "ymodc=y_train['rating']\n",
    "regC.fit(Xmodc,ymodc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea063a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model D\n",
    "regD=linear_model.LinearRegression()\n",
    "Xmodd=y_train[['gender','helpfulness']]\n",
    "ymodd=y_train['rating']\n",
    "regD.fit(Xmodd,ymodd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb331d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "KATSn7hYlA_Z",
   "metadata": {
    "id": "KATSn7hYlA_Z"
   },
   "source": [
    "### Evaluate Models\n",
    "* Evaluate the performance of the four models with two metrics, including MSE and Root MSE\n",
    "* Print the results of the four models regarding the two metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4fU8GPS9lA_Z",
   "metadata": {
    "id": "4fU8GPS9lA_Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.7690740179517055\n",
      "Root MSE: 1.3300654186737229\n"
     ]
    }
   ],
   "source": [
    "#Evaluation For Model A\n",
    "X_test1=X_test[['category','review']]\n",
    "y_test1=X_test['rating']\n",
    "\n",
    "predicted=regA.predict(X_test1)\n",
    "mse1=((np.array(y_test1) - predicted)**2).sum()/len(y_test1)\n",
    "root_mse1=np.sqrt(mse1)\n",
    "print(\"MSE:\",mse1)\n",
    "print(\"Root MSE:\",root_mse1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "266bbed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.8412549895856636\n",
      "Root MSE: 1.356928513071217\n"
     ]
    }
   ],
   "source": [
    "#Evaluation For Model B\n",
    "X_test2=X_test[['gender','helpfulness']]\n",
    "y_test2=X_test['rating']\n",
    "\n",
    "predicted=regB.predict(X_test2)\n",
    "mse2=((np.array(y_test2) - predicted)**2).sum()/len(y_test2)\n",
    "root_mse2=np.sqrt(mse2)\n",
    "print(\"MSE:\",mse2)\n",
    "print(\"Root MSE:\", root_mse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33c9f176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.7588975359805044\n",
      "Root MSE: 1.3262343442923292\n"
     ]
    }
   ],
   "source": [
    "#Evaluation For Model c\n",
    "X_test3=y_test[['category','review']]\n",
    "y_test3=y_test['rating']\n",
    "\n",
    "predicted=regC.predict(X_test3)\n",
    "mse3=((np.array(y_test3) - predicted)**2).sum()/len(y_test3)\n",
    "root_mse3=np.sqrt(mse3)\n",
    "print(\"MSE:\",mse3)\n",
    "print(\"Root MSE:\",np.sqrt(mse3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93f4ac26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.8109460127732366\n",
      "Root MSE: 1.3457139416581954\n"
     ]
    }
   ],
   "source": [
    "#Evaluation For Model D\n",
    "X_test4=y_test[['gender','helpfulness']]\n",
    "y_test4=y_test['rating']\n",
    "\n",
    "predicted=regD.predict(X_test4)\n",
    "mse4=((np.array(y_test4) - predicted)**2).sum()/len(y_test4)\n",
    "root_mse4=np.sqrt(mse4)\n",
    "print(\"MSE:\",mse4)\n",
    "print(\"Root MSE:\",root_mse4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y9jx-eY6lA_a",
   "metadata": {
    "id": "Y9jx-eY6lA_a"
   },
   "source": [
    "### Visualize, Compare and Analyze the Results\n",
    "* Visulize the results, and perform ___insightful analysis___ on the obtained results. For better visualization, you may need to carefully set the scale for the y-axis.\n",
    "* Normally, the model trained with most correlated features and more training data will get better results. Do you obtain the similar observations? If not, please ___explain the possible reasons___."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7cc9b308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.769074</td>\n",
       "      <td>1.330065</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.841255</td>\n",
       "      <td>1.356929</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.758898</td>\n",
       "      <td>1.326234</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.810946</td>\n",
       "      <td>1.345714</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mse      rmse Model\n",
       "0  1.769074  1.330065     A\n",
       "1  1.841255  1.356929     B\n",
       "2  1.758898  1.326234     C\n",
       "3  1.810946  1.345714     D"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse=[mse1,mse2,mse3,mse4]\n",
    "mse_root=[root_mse1,root_mse2,root_mse3,root_mse4]\n",
    "data_mse = pd.DataFrame({'mse': mse, 'rmse': mse_root, 'Model': [\"A\", \"B\", \"C\", \"D\"]})\n",
    "data_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e45e70",
   "metadata": {},
   "source": [
    "## MSE (lowest accurate to most accurate)\n",
    "- Model B has an MSE of 1.841255 used 90% of the testing data and is the most correlated, hence why it has the highest mse\n",
    "- Model D has an MSE of 1.810946 used 10% of the testing data and is the most correlated hence why it has the highest mse \n",
    "- Model A has an MSE of 1.769074 used 90% of the testing data and is the least correlated hence why it has the lowest mse\n",
    "- Model C has an MSE of 1.758898 used 10% of the testing data and is the least correlated hence why it has the lowest mse\n",
    "\n",
    "## Model A and B\n",
    "- Both Models were trained using the same data but however they had different correlations hence why correlations can have a massive impact on the mse. As the Graph shows Model A(Blue) and Model B(orange), model B has the highest MSE.\n",
    "## Model C  and D\n",
    "- Both Models were trained using the same data but however they had different correlations hence why correlations can have a massive impact on the mse. As the Graph shows Model C(green) and Model D(red), model D has the highest MSE.\n",
    "## Model C and A\n",
    "- Both Models were trained using same correlations but however they had different testing data sizes resulting in one have a higher mse then the other. As the Graph shows Model C(green) and Model A(blue), model A has the highest MSE.\n",
    "## Model B and D\n",
    "- Both Models were trained using same correlations but however they had different testing data sizes resulting in one have a higher mse then the other. As the Graph shows Model B(orange) and Model D(red), model B has the highest MSE.\n",
    "\n",
    "## Overall\n",
    "- As shown by the graphs of MSE scores, the corelation does matter but the freatue of the graphs that matter the most is size of training data which have slightly affected the mse scores.\n",
    "\n",
    "## This can Also be seen with the root mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3TNAIGDilA_a",
   "metadata": {
    "id": "3TNAIGDilA_a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='mse', ylabel='Model'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=data_mse, y='Model', x='mse')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22b95f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot=sns.barplot(data=data_mse, y='Model', x='rmse')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
